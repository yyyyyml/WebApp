## 文献总结




### 基本信息
Title: Boosting the Throughput and Accelerator Utilization of Specialized CNN Inference Beyond Increasing Batch Size (提升专用CNN推理的吞吐量和加速器利用率——超越增加批处理大小)

Authors: Unknown

Affiliation: Unknown

Keywords: specialized CNN, accelerator utilization, throughput, batch size (专用CNN，加速器利用率，吞吐量，批处理大小)

Urls: Paper link: [Link](xxx), Github code: None (论文链接: [链接](xxx), Github代码链接: 无)


### 简要总结
Summary: 

- (1): 本文研究的背景是提高专用CNN推理的吞吐量和加速器利用率。

- (2): 过去的方法主要是增加批处理大小来提高吞吐量和加速器利用率。然而，这种方法存在一些问题。本文的方法提出了一种新的研究方法，旨在解决这些问题。

- (3): 本文提出了一种折叠（Folding）的方法，通过对输入进行转换，从而增加算术强度（arithmetic intensity），提高加速器的利用率。

- (4): 本文在微软和NoScope视频处理系统上评估了折叠CNN的性能。结果表明，折叠CNN可以提高专用CNN的GPU利用率和吞吐量，同时保持较高的准确性。这些结果支持了本文的目标。





### 详细总结
Conclusion: 

- (1):重要性：这篇文章的重要性在于提出了一种新的方法来提高专用CNN推理的吞吐量和加速器利用率。这对于深度学习领域的研究和实际应用具有重要意义。

- (2):创新点: 本文的创新点在于引入了折叠方法来增加算术强度，从而提高加速器的利用率。相比于过去的方法只关注增加批处理大小，这种方法能够更有效地提升吞吐量和加速器利用率。

- (3):性能: 本文在微软和NoScope视频处理系统上评估了折叠CNN的性能。结果表明，折叠CNN可以显著提高专用CNN的GPU利用率和吞吐量，并且在保持较高准确性的同时取得了良好的效果。这证明了本文方法在性能上的优势。

- (4):工作量: 本文所提出的方法需要对输入进行折叠处理，增加算术强度，这可能会增加一定的工作量。然而，由于结果表明该方法在性能上的优势，这种额外工作量可以被认为是合理的投入。

通过对这篇论文的综合审查，我们可以肯定地说，这项研究具有重要意义，创新性地引入了折叠方法用于提高专用CNN推理的吞吐量和加速器利用率。在性能方面，折叠CNN在GPU利用率和吞吐量上取得了显著改进，并且保持了高准确性。虽然这种方法可能会增加一些工作量，但它所带来的性能优势证明了这种投入是合理的。总体而言，这篇文章对深度学习领域的研究和应用有着重要的贡献。




